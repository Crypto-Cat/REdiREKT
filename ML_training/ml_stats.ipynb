{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from os import path, getcwd, system, mkdir\n",
    "from datetime import datetime\n",
    "from shutil import rmtree\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "import sklearn as sk\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import LSTM, Masking\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('default')\n",
    "\n",
    "# Will clear tensorflow graph (so that brand new model is created)\n",
    "tf.keras.backend.clear_session()\n",
    "tf.reset_default_graph()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df = pd.read_csv(path.join(getcwd(), \"training_data/features.csv\"))\n",
    "\n",
    "# # Convert TLD to category codes\n",
    "# df[\"tld\"] = df[\"tld\"].astype(\"category\").cat.codes\n",
    "\n",
    "# # Scale data between 0 and 1\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # All features\n",
    "# features_to_scale = df.copy().drop(['classification', 'sample', 'redir_no'], axis=1)\n",
    "\n",
    "# # Normalise\n",
    "# normalised = pd.DataFrame(scaler.fit_transform(features_to_scale), columns=features_to_scale.columns, index=features_to_scale.index)\n",
    "\n",
    "# # Rebuild normalised dataframe\n",
    "# df = pd.concat([df[['classification', 'sample', 'redir_no']], normalised], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "\n",
    "# Only process mal/ben?\n",
    "#df = df[df['classification'] == 1]\n",
    "#df = df[df['redir_no'] != 0]\n",
    "\n",
    "# Extract features we want\n",
    "#df = df.filter(['classification','sample', 'redir_referrer', 'redir_location', 'redir_html', 'redir_js', 'redir_iframe','redir_subdomain', 'redir_concat', 'redir_base64', 'redir_unknown']) # Redirect\n",
    "df = df.filter(['classification','sample','port_80', 'domain_is_ip','domain_len_avg','domain_entropy_avg','uri_len_avg','uri_entropy_avg','uri_ch_slash_avg', 'uri_ch_amp_avg','uri_ch_dash_avg','uri_ch_plus_avg']) # URL\n",
    "#df = df.filter(['classification','sample','bytes_shockwave_avg', 'bytes_x-dosexec_avg', 'bytes_java_avg', 'bytes_silverlight_avg', 'bytes_javascript_avg', 'bytes_xml_avg', 'bytes_zip_avg', 'bytes_image_avg', 'bytes_html_avg']) # Content\n",
    "#df = df.filter(['sample','redir_time', 'node_depth', 'response_len_avg', 'port_80', 'domain_is_ip']) # Extra\n",
    "#df = df.drop(['tld','response_len_total','bytes_shockwave_total','bytes_x-dosexec_total','bytes_java_total', 'bytes_silverlight_total','bytes_javascript_total','bytes_xml_total','bytes_zip_total','bytes_image_total','bytes_html_total','uri_ch_slash_total', 'uri_ch_amp_avg','uri_ch_dash_avg','redir_no'], axis=1) # All\n",
    "\n",
    "def first_last(a):\n",
    "    return a.iloc[[-1]]\n",
    "\n",
    "# Group samples by name\n",
    "# tld = tld.groupby(['sample','tld'],sort=False)\n",
    "#tld.value_counts().to_csv('node0_tld_benign_counts.csv')\n",
    "# tld.describe().to_csv(\"tld_benign.csv\")\n",
    "df = df.groupby('sample',sort=False).mean()\n",
    "\n",
    "#df.to_csv('node1-n_URI_malicious.csv')\n",
    "\n",
    "corrmat = df.corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(corrmat,cmap='viridis',annot=True,linewidths=0.5)\n",
    "\n",
    "# print(df.describe())\n",
    "# df.describe().to_csv('describe_features.csv')\n",
    "\n",
    "# df.hist(figsize=(15,15))\n",
    "# pd.plotting.hist_frame(df, figsize=(15,15))\n",
    "#pd.plotting.hist_frame(tld, figsize=(15,15))\n",
    "\n",
    "# Assign colours to classifications\n",
    "# color_wheel = {1: \"#0392cf\", \n",
    "#                2: \"#ee4035\"}\n",
    "# colors = df['classification'].map(lambda x: color_wheel.get(x + 1))\n",
    "# pd.plotting.scatter_matrix(df.drop(['classification'], axis=1), color=colors, alpha=0.6, figsize=(15, 15), diagonal='hist')\n",
    "\n",
    "#pd.plotting.scatter_matrix(df, figsize=(15,15))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "\n",
    "# Only process mal/ben?\n",
    "df = df[df['classification'] == 0]\n",
    "\n",
    "# Extract features we want\n",
    "#df = df.filter(['classification','sample', 'redir_referrer', 'redir_location', 'redir_html', 'redir_js', 'redir_iframe','redir_subdomain', 'redir_concat', 'redir_base64', 'redir_unknown']) # Redirect\n",
    "#df = df.filter(['classification','sample','domain_len_avg', 'domain_entropy_avg', 'uri_len_avg', 'uri_entropy_avg', 'uri_ch_slash_avg', 'uri_ch_amp_avg', 'uri_ch_dash_avg', 'uri_ch_plus_avg']) # URL\n",
    "#df = df.filter(['classification','sample','bytes_shockwave_avg', 'bytes_x-dosexec_avg', 'bytes_java_avg', 'bytes_silverlight_avg', 'bytes_javascript_avg', 'bytes_xml_avg', 'bytes_zip_avg', 'bytes_image_avg', 'bytes_html_avg']) # Content\n",
    "tld = df.filter(['sample','tld'])\n",
    "df = df.filter(['sample','redir_time', 'node_depth', 'response_len_avg', 'port_80', 'domain_is_ip']) # Extra\n",
    "#df = df.drop(['tld','response_len_total','bytes_shockwave_total','bytes_x-dosexec_total','bytes_java_total', 'bytes_silverlight_total','bytes_javascript_total','bytes_xml_total','bytes_zip_total','bytes_image_total','bytes_html_total','uri_ch_slash_total', 'uri_ch_amp_avg','uri_ch_dash_avg','redir_no'], axis=1) # All\n",
    "\n",
    "# Group samples by name\n",
    "tld = tld.groupby('tld',sort=False)\n",
    "tld.describe().to_csv(\"tld_malicious.csv\")\n",
    "#df = df.groupby('sample',sort=False).mean()\n",
    "\n",
    "# print(df.loc[1])\n",
    "# print(df.shape)\n",
    "\n",
    "# print(df.describe())\n",
    "# df.describe().to_csv('describe_features.csv')\n",
    "\n",
    "# df.hist(figsize=(15,15))\n",
    "# pd.plotting.hist_frame(df, figsize=(15,15))\n",
    "#pd.plotting.hist_frame(tld, figsize=(15,15))\n",
    "\n",
    "# Assign colours to classifications\n",
    "# color_wheel = {1: \"#0392cf\", \n",
    "#                2: \"#ee4035\"}\n",
    "# colors = df['classification'].map(lambda x: color_wheel.get(x + 1))\n",
    "# pd.plotting.scatter_matrix(df.drop(['classification'], axis=1), color=colors, alpha=0.6, figsize=(15, 15), diagonal='hist')\n",
    "\n",
    "#pd.plotting.scatter_matrix(df, figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "# Use LaTeX fonts in the plot\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "# Get the figure\n",
    "f = plt.figure()\n",
    "\n",
    "# Extract features we want\n",
    "# df = df.filter(['classification','sample', 'redir_referrer', 'redir_location', 'redir_html', 'redir_js', 'redir_iframe','redir_subdomain', 'redir_concat', 'redir_base64', 'redir_unknown']) # Redirect\n",
    "df = df.filter(['classification','sample','domain_len_avg', 'domain_entropy_avg', 'uri_len_avg', 'uri_entropy_avg', 'uri_ch_slash_avg', 'uri_ch_amp_avg', 'uri_ch_dash_avg', 'uri_ch_plus_avg']) # URL\n",
    "# df = df.filter(['classification','sample','bytes_shockwave_avg', 'bytes_x-dosexec_avg', 'bytes_java_avg', 'bytes_silverlight_avg', 'bytes_javascript_avg', 'bytes_xml_avg', 'bytes_zip_avg', 'bytes_image_avg', 'bytes_html_avg']) # Content\n",
    "# df = df.filter(['classification','sample','redir_time', 'node_depth', 'response_len_avg', 'port_80', 'domain_is_ip']) # Extra\n",
    "#df = df.drop(['tld','response_len_total','bytes_shockwave_total','bytes_x-dosexec_total','bytes_java_total', 'bytes_silverlight_total','bytes_javascript_total','bytes_xml_total','bytes_zip_total','bytes_image_total','bytes_html_total','uri_ch_slash_total', 'uri_ch_amp_avg','uri_ch_dash_avg','redir_no'], axis=1) # All\n",
    "\n",
    "# Group samples by name\n",
    "df = df.groupby('sample',sort=False).mean()\n",
    "\n",
    "# Only process mal/ben?\n",
    "mal_df = df[df['classification'] == 1]\n",
    "ben_df = df[df['classification'] == 0]\n",
    "\n",
    "# Density ensures uneven dataset (mal:ben) is accounted for\n",
    "kwargs = dict(alpha=0.7, density=True, stacked=True, bins=10)\n",
    "plt.hist(ben_df['uri_ch_plus_avg'], **kwargs, label='benign', color='blue')\n",
    "plt.hist(mal_df['uri_ch_plus_avg'], **kwargs, label='malicious', color='red')\n",
    "plt.title(r'URI ampersand count', fontsize=11)\n",
    "plt.xlim(0,5)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "orig_nbformat": 2,
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
